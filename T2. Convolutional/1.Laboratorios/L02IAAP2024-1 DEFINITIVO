{"cells":[{"cell_type":"markdown","source":["# APRENDIZAJE PROFUNDO\n","# Redes Neuronales Convolucionales\n","# 2024-1\n","# Laboratorio 2/3\n","# Presentado por:\n"," - Juan Pablo Daza Pereira\n"," - Juan Sebastian Camargo Sanchez"],"metadata":{"id":"MGaayL8W3it_"}},{"cell_type":"markdown","source":["# **InteractiveShell**"],"metadata":{"id":"gFS6J6h53YEZ"}},{"cell_type":"code","source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","from platform import python_version\n","'Python ' + python_version()\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import convolve2d"],"metadata":{"id":"S66jUQGbCWmD","executionInfo":{"status":"ok","timestamp":1716772983115,"user_tz":300,"elapsed":2564,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# **Código**"],"metadata":{"id":"1-SP8wte5J-v"}},{"cell_type":"code","source":["# PUNTO UNO. IMPLEMENTACIÓN. ADELANTE. CAPA CONVOLUCIÓN 2D.\n","def add_pad(data_in, pad):\n","    return np.pad(data_in, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='constant')\n","#------------------------------------------------------------------------------------------\n","def one_convolution(X, W, b):\n","    return np.sum(X * W) + b\n","#------------------------------------------------------------------------------------------\n","def forward_convolution_step(data_in, specification, parameters):\n","    c_filter = specification['c_filter']\n","    c_filters = specification['c_filters']\n","    c_stride = specification['c_stride']\n","    c_pad = specification['c_pad']\n","\n","    W = parameters['W']\n","    b = parameters['b']\n","\n","    m, n_H_prev, n_W_prev, n_C_prev = data_in.shape\n","\n","    n_H = int((n_H_prev - c_filter + 2 * c_pad) / c_stride) + 1\n","    n_W = int((n_W_prev - c_filter + 2 * c_pad) / c_stride) + 1\n","\n","    data_out = np.zeros((m, n_H, n_W, c_filters))\n","\n","    data_padded = np.pad(data_in, ((0, 0), (c_pad, c_pad), (c_pad, c_pad), (0, 0)), mode='constant')\n","    print(data_padded.shape)\n","\n","    # Iteraciones\n","    for i in range(m):\n","        for h in range(n_H):\n","            vert_start = h * c_stride\n","            vert_end = vert_start + c_filter\n","            for w in range(n_W):\n","                horiz_start = w * c_stride\n","                horiz_end = horiz_start + c_filter\n","                for c in range(c_filters):\n","                    data_slice = data_padded[i, vert_start:vert_end, horiz_start:horiz_end, :]\n","                    weights = W[..., c]\n","                    biases = b[..., c]\n","                    data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n","\n","    return data_out\n","#------------------------------------------------------------------------------------------\n","def forward_activation_step(data_in, specification):\n","    activation_type = specification['activation']\n","    if activation_type == 'Relu':\n","        data_out = np.maximum(0, data_in)\n","    elif activation_type == 'Sigmoid':\n","        data_out = 1 / (1 + np.exp(-data_in))\n","    elif activation_type == 'Tanh':\n","        data_out = np.tanh(data_in)\n","    else:\n","        raise ValueError(\"Invalid activation type. Supported activations: 'Relu', 'Sigmoid', 'Tanh'.\")\n","\n","    return data_out\n","#------------------------------------------------------------------------------------------\n","def forward_pooling_step(data_in, specification):\n","    p_filter = specification['p_filter']\n","    p_stride = specification['p_stride']\n","    p_function = specification['p_function']\n","\n","    m, n_H_prev, n_W_prev, n_C_prev = data_in.shape\n","\n","    n_H = int((n_H_prev - p_filter) / p_stride) + 1\n","    n_W = int((n_W_prev - p_filter) / p_stride) + 1\n","\n","    data_out = np.zeros((m, n_H, n_W, n_C_prev))\n","\n","    # Iteraciones\n","    for i in range(m):\n","        for h in range(n_H):\n","            for w in range(n_W):\n","                vert_start = h * p_stride\n","                vert_end = vert_start + p_filter\n","                horiz_start = w * p_stride\n","                horiz_end = horiz_start + p_filter\n","                data_slice = data_in[i, vert_start:vert_end, horiz_start:horiz_end, :]\n","\n","                # Se aplica el pooling\n","                if p_function == 'max':\n","                    data_out[i, h, w, :] = np.max(data_slice, axis=(0, 1))\n","                elif p_function == 'average':\n","                    data_out[i, h, w, :] = np.mean(data_slice, axis=(0, 1))\n","                else:\n","                    raise ValueError(\"Invalid pooling function. Supported functions: 'max', 'average'.\")\n","\n","    return data_out\n","#------------------------------------------------------------------------------------------\n","def forward_convolutional(data_in, specification, parameters):\n","    data_conv = forward_convolution_step(data_in, specification, parameters)\n","    data_activation = forward_activation_step(data_conv, specification)\n","    data_out = forward_pooling_step(data_activation, specification)\n","\n","    cache = (data_in, (data_conv, data_activation))\n","    return data_out, cache\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","# PUNTO TRES. IMPLEMENTACIÓN. ATRAS. CAPA CONVOLUCIÓN.\n","def backward_pooling_step(gradient_in, specification, cache):\n","    X = cache\n","    m, n_H_prev, n_W_prev, n_C_prev = X.shape\n","    m, n_H, n_W, n_C = gradient_in.shape\n","\n","    gradient_out = np.zeros(X.shape)\n","\n","    # Iteraciones\n","    for i in range(m):\n","        for h in range(n_H):\n","            for w in range(n_W):\n","                vert_start = h\n","                vert_end = vert_start + specification['p_filter']\n","                horiz_start = w\n","                horiz_end = horiz_start + specification['p_filter']\n","\n","                if specification['p_function'] == 'max':\n","                    data_slice = X[i, vert_start:vert_end, horiz_start:horiz_end, :]\n","                    mask = (data_slice == np.max(data_slice, axis=(0, 1)))\n","                    gradient_out[i, vert_start:vert_end, horiz_start:horiz_end, :] += mask * gradient_in[i, h, w, :]\n","                elif specification['p_function'] == 'avg':\n","                    avg_grad = gradient_in[i, h, w, :] / (specification['p_filter'] ** 2)\n","                    gradient_out[i, vert_start:vert_end, horiz_start:horiz_end, :] += np.ones((specification['p_filter'], specification['p_filter'], n_C_prev)) * avg_grad\n","\n","    return gradient_out\n","#------------------------------------------------------------------------------------------\n","def backward_activation_step(gradient_in, specification, cache):\n","    activation_type = specification['activation']\n","    if not cache:\n","        if activation_type == 'Relu':\n","          grad_out = np.where(gradient_in > 0, 1, 0)  # Convertir valores positivos a 1 y valores negativos a 0\n","        elif activation_type == 'Sigmoid':\n","          grad_out = gradient_in * (gradient_in * (1 - cache[0]))\n","        elif activation_type == 'Tanh':\n","          grad_out = gradient_in * (1 - gradient_in**2)\n","        else:\n","          raise ValueError(\"Invalid activation type. Supported activations: 'Relu', 'Sigmoid', 'Tanh'.\")\n","    else:\n","        if activation_type == 'Relu':\n","            grad_out = np.where(cache[0] > 0, gradient_in, 0)  # Aplicar ReLU y redondear a 1 o 0\n","        elif activation_type == 'Sigmoid':\n","            grad_out = gradient_in * (cache[0] * (1 - cache))\n","        elif activation_type == 'Tanh':\n","            grad_out = gradient_in * (1 - cache[0]**2)\n","        else:\n","            raise ValueError(\"Invalid activation type. Supported activations: 'Relu', 'Sigmoid', 'Tanh'.\")\n","\n","    return grad_out\n","    # Tomado de: https://jmyao17.github.io/Machine_Learning/Neural_Network/CNN-1/CNN_Build.html\n","    # Convolution Model - Step by Step -v2. github\n","#------------------------------------------------------------------------------------------\n","def backward_convolution_step(gradient_in, specification, cache):\n","    # Desempaquetar cache\n","    (A_p, W) = cache\n","\n","    # Obtener dimensiones\n","    (m, n_H_prev, n_W_prev, n_C_prev) = A_p.shape\n","    (f, f, n_C_prev, n_C) = W.shape\n","\n","    # Retrieve dimensions from dZ's shape\n","    (m, n_H, n_W, n_C) = gradient_in.shape\n","\n","    # Desempaquetar specification\n","    c_filter = specification['c_filter']\n","    c_filters = specification['c_filters']\n","    c_stride = specification['c_stride']\n","    c_pad = specification['c_pad']\n","\n","    # Initialize dA_prev, dW, db with the correct shapes\n","    dA_prev = np.zeros(A_p.shape)\n","    dW = np.zeros(W.shape)\n","    db = np.sum(gradient_in, axis=(0,1,2), keepdims=True)\n","\n","    # Pad A_prev and dA_prev\n","    data_in_pad = add_pad(A_p, c_pad)\n","    dA_prev_pad = add_pad(dA_prev, c_pad)\n","\n","    # Rellenar el gradiente dA_prev usando la fórmula de retropropagación\n","    for i in range(m):                       # loop sobre los ejemplos de entrenamiento\n","        a_prev_pad = data_in_pad[i]\n","        da_prev_pad = dA_prev_pad[i]\n","\n","        for h in range(n_H_prev):           # loop sobre la altura del volumen de salida\n","            for w in range(n_W_prev):       # loop sobre la anchura del volumen de salida\n","                for c in range(n_C):        # loop sobre los canales del volumen de salida\n","                    # Encontrar las esquinas de la ventana de inicio\n","                    vert_start = h * c_stride\n","                    vert_end = vert_start + c_filter\n","                    horiz_start = w * c_stride\n","                    horiz_end = horiz_start + c_filter\n","\n","                    # Use the corners to define the slice from a_prev_pad\n","                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n","\n","                    # Update gradients for the window and the filter's parameters using the code formulas given above\n","                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += (W[..., c] * gradient_in[i, h, w, c])\n","                    dW[..., c] += a_slice * gradient_in[i, h, w, c]\n","\n","        dA_prev[i, :, :, :] = da_prev_pad[c_pad:-c_pad, c_pad:-c_pad, :]\n","\n","    # Making sure your output shape is correct\n","    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n","\n","    parameters = {'W':dW,'b':db}\n","\n","    #return dA_prev, parameters\n","    return dA_prev, parameters\n","    # Tomado de: https://jmyao17.github.io/Machine_Learning/Neural_Network/CNN-1/CNN_Build.html\n","    # Convolution Model - Step by Step -v2. github\n","#------------------------------------------------------------------------------------------\n","def backward_convolutional(gradient_in, specification, cache):\n","    (I,(A_p,W)) = cache\n","    # Retropropagación del paso de pooling\n","    gradient_out_pool = backward_pooling_step(gradient_in, specification, (I))\n","    # Retropropagación del paso de activación\n","    gradient_out_act = backward_activation_step(gradient_out_pool, specification, ())\n","    # Retropropagación del paso de convolución\n","    gradient_out_conv, parameters_gradient_conv = backward_convolution_step(gradient_out_act, specification, (A_p,W))\n","\n","    return gradient_out_conv, parameters_gradient_conv\n","    # Tomado de: https://jmyao17.github.io/Machine_Learning/Neural_Network/CNN-1/CNN_Build.html\n","    # Convolution Model - Step by Step -v2. github\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------------------------------\n","#PUNTO CUATRO. CAPA CONVOLUCIÓN 2D A CAPA DENSA\n","def to_dense(data_in):\n","    m, n_H, n_W, n_C = data_in.shape\n","    data_out = np.reshape(data_in, (m, n_H * n_W * n_C)).T\n","    return data_out"],"metadata":{"id":"huBdLLKg5OxX","executionInfo":{"status":"ok","timestamp":1716773556799,"user_tz":300,"elapsed":192,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bx96YLzk26Kk"},"source":["# **Forward**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A18J_QOs26Ko","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225432489,"user_tz":300,"elapsed":254,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"df97f2bb-c5f4-4afc-c448-b9606f267a92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.62434536, -0.52817175],\n","       [ 0.86540763,  1.74481176]])"]},"metadata":{},"execution_count":5},{"output_type":"execute_result","data":{"text/plain":["array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","         0.        ],\n","       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","         0.        ],\n","       [ 0.        ,  0.        ,  1.62434536, -0.52817175,  0.        ,\n","         0.        ],\n","       [ 0.        ,  0.        ,  0.86540763,  1.74481176,  0.        ,\n","         0.        ],\n","       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","         0.        ],\n","       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","         0.        ]])"]},"metadata":{},"execution_count":5}],"source":["#test: add_pad\n","np.random.seed(1)\n","X = np.random.randn(4, 2, 2, 2)\n","X[0,:,:,0]\n","Y = add_pad(X, 2)\n","Y[0,:,:,0]\n","assert Y.shape==(4,6,6,2), \"Wrong size\"\n","assert np.sum(Y) == np.sum(X), \"Wrong sum values\"\n","assert np.all(Y[0,2:4,2:4,0]==X[0,:,:,0]), \"Wrong values\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKl2GXCG26Kp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225433183,"user_tz":300,"elapsed":236,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"dc880a3d-9535-47a1-9db0-80d3e59a4fc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["C = [[[-6.99908945]]]\n"]}],"source":["#test: one_convolution\n","np.random.seed(1)\n","X_slide = np.random.randn(4, 4, 3)\n","W = np.random.randn(4, 4, 3)\n","b = np.random.randn(1, 1, 1)\n","C = one_convolution(X_slide, W, b)\n","print(\"C =\", C)\n","assert np.isclose(C, -6.999089450680221), \"Wrong value\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FH2rH9Jv26Kp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225433184,"user_tz":300,"elapsed":6,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"c9b35cc9-e481-42fd-9b28-bdf546ecf5d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 7, 9, 4)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3c771ff44ca1>:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([-2.17796037,  8.07171329, -0.5772704 ,  3.36286738,  4.48113645,\n","       -2.89198428, 10.99288867,  3.03171932])"]},"metadata":{},"execution_count":7}],"source":["#test: forward_convolution_step\n","np.random.seed(1)\n","X = np.random.randn(2, 5, 7, 4)\n","W = np.random.randn(3, 3, 4, 8)\n","b = np.random.randn(1, 1, 1, 8)\n","s={'c_filter': 3,'c_channels': 4, 'c_filters': 8,'c_stride':2, 'c_pad':1}\n","p={'W':W, 'b':b }\n","Y= forward_convolution_step(X,s,p)\n","Y[0,2,1]\n","assert np.all(np.isclose(Y[0,2,1], np.array([-2.17796037,8.07171329,-0.5772704, 3.36286738,4.48113645,-2.89198428,10.99288867,3.03171932]))), \"Wrong value\""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"cTCcDped26Kp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225433184,"user_tz":300,"elapsed":5,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"f094f029-d96c-486a-eb79-e86796666352"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.62434536, -0.52817175,  0.86540763],\n","       [ 1.74481176,  0.3190391 ,  1.46210794],\n","       [-0.3224172 ,  1.13376944, -0.17242821]])"]},"metadata":{},"execution_count":8},{"output_type":"execute_result","data":{"text/plain":["array([[1.62434536, 0.        , 0.86540763],\n","       [1.74481176, 0.3190391 , 1.46210794],\n","       [0.        , 1.13376944, 0.        ]])"]},"metadata":{},"execution_count":8}],"source":["#test: forward_activation_step\n","np.random.seed(1)\n","s={'activation':'Relu'}\n","X = np.random.randn(4, 3, 3, 2)\n","X[0,:,:,0]\n","Y=forward_activation_step(X,s)\n","Y[0,:,:,0]\n","assert np.all(np.isclose(Y[0,:,:,0], [[1.62434536, 0., 0.86540763],[1.74481176, 0.3190391 , 1.46210794],[0.        , 1.13376944, 0.        ]])), \"Wrong value\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"je9CYcnF26Kq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225433185,"user_tz":300,"elapsed":5,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"4275ea79-dec1-4e6f-e9b1-d8b58322ed90"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.62434536, -1.07296862,  1.74481176, -0.24937038, -0.3224172 ,\n","        -1.09989127],\n","       [ 0.04221375,  1.14472371,  0.90085595, -0.93576943, -0.69166075,\n","        -0.84520564],\n","       [-1.11731035,  0.74204416, -0.74715829, -0.63699565,  0.12015895,\n","        -0.35224985],\n","       [-0.20889423,  0.93110208, -0.75439794, -0.29809284,  1.13162939,\n","        -1.39649634],\n","       [ 0.16003707, -2.02220122,  0.23009474, -0.20075807,  0.19829972,\n","         0.37756379],\n","       [ 1.19891788, -0.63873041, -0.34385368,  0.69803203,  0.40349164,\n","         0.16938243]])"]},"metadata":{},"execution_count":9},{"output_type":"execute_result","data":{"text/plain":["array([[ 1.62434536,  1.74481176, -0.3224172 ],\n","       [ 0.93110208, -0.29809284,  1.13162939],\n","       [ 1.19891788,  0.69803203,  0.40349164]])"]},"metadata":{},"execution_count":9}],"source":["#test: forward_pooling_step\n","np.random.seed(1)\n","X = np.random.randn(2, 6, 6, 3)\n","X[0,:,:,0]\n","s= {'p_filter':2, 'p_stride' : 2, 'p_function': 'max'}\n","Y = forward_pooling_step(X, s)\n","Y[0,:,:,0]\n","assert Y.shape == (2,3,3,3), \"Wrong shape\"\n","assert np.all(np.isclose(Y[0,:,:,0],[[ 1.62434536,  1.74481176, -0.3224172 ],[ 0.93110208, -0.29809284,  1.13162939],[ 1.19891788,  0.69803203,  0.40349164]])), \"Wrong values\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcbvdmLZ26Kq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225433471,"user_tz":300,"elapsed":290,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"5d322bcb-deec-47da-9f0c-217a194c79ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 7, 9, 4)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3c771ff44ca1>:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[4.29865415, 3.40859795]])"]},"metadata":{},"execution_count":10}],"source":["#test: forward_convolutional\n","np.random.seed(1)\n","X = np.random.randn(2, 5, 7, 4)\n","W = np.random.randn(3, 3, 4, 8)\n","b = np.random.randn(1, 1, 1, 8)\n","s={'c_filter': 3,'c_channels': 4, 'c_filters': 8,'c_stride':2, 'c_pad':1, 'activation':'Relu', 'p_filter':2, 'p_stride' : 2, 'p_function': 'max'}\n","p={'W':W, 'b':b }\n","Y,_=forward_convolutional(X, s, p)\n","Y[0,:,:,1]\n","assert Y.shape==(2,1,2,8), \"Wrong size\"\n","assert np.all(np.isclose(Y[0,:,:,1],[[4.2986541519, 3.4085979528]])), \"Wrong values\""]},{"cell_type":"markdown","metadata":{"id":"8wEnTVws26Kq"},"source":["# **Backward**"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Db3Lw-3x26Kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225434231,"user_tz":300,"elapsed":2,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"1c278bef-1287-4812-d39f-c7565ccd3ba2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.        ,  0.        ],\n","       [ 5.05844394, -1.68282702],\n","       [ 0.        ,  0.        ]])"]},"metadata":{},"execution_count":11},{"output_type":"execute_result","data":{"text/plain":["array([[ 0.08485462,  0.2787552 ],\n","       [ 1.26461098, -0.25749373],\n","       [ 1.17975636, -0.53624893]])"]},"metadata":{},"execution_count":11}],"source":["#test: backward_pooling_step\n","np.random.seed(1)\n","X = np.random.randn(5, 5, 3, 2)\n","s = {'p_stride' : 1, 'p_filter': 2, 'p_function':'max'}\n","Y = forward_pooling_step(X, s)\n","g_X = np.random.randn(5, 4, 2, 2)\n","g_Y = backward_pooling_step(g_X, s, (X))\n","g_Y[1,1]\n","assert g_Y.shape == (5, 5, 3, 2), \"Wrong shape max\"\n","assert np.allclose(g_Y[1, 1], [[0, 0],[ 5.05844394, -1.68282702],[ 0, 0]]), \"Wrong values max\"\n","s['p_function']='avg'\n","g_Y = backward_pooling_step(g_X, s, (X))\n","g_Y[1, 1]\n","assert g_Y.shape == (5, 5, 3, 2), \"Wrong shape avg\"\n","assert np.allclose(g_Y[1, 1], [[0.08485462,  0.2787552],\n","                               [1.26461098, -0.25749373],\n","                               [1.17975636, -0.53624893]]), \"Wrong values avg\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qm8rUD7Y26Kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225434468,"user_tz":300,"elapsed":3,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"78c8c00d-0b7f-42d0-c7de-79d76f06425b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.62434536, -0.52817175,  0.86540763],\n","       [ 1.74481176,  0.3190391 ,  1.46210794],\n","       [-0.3224172 ,  1.13376944, -0.17242821]])"]},"metadata":{},"execution_count":12},{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 1],\n","       [1, 1, 1],\n","       [0, 1, 0]])"]},"metadata":{},"execution_count":12}],"source":["#test: backward_activation_step\n","np.random.seed(1)\n","s={'activation':'Relu'}\n","cache=()\n","g_X = np.random.randn(4, 3, 3, 2)\n","g_X[0,:,:,0]\n","g_Y=backward_activation_step(g_X,s,cache)\n","g_Y[0,:,:,0]\n","assert g_Y.shape == (4, 3, 3, 2), \"Wrong shape\"\n","assert np.allclose(g_Y[0,:,:, 0],[[1, 0, 1],[1, 1, 1],[0, 1, 0]]), \"Wrong values avg\""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"pr6gdRQz26Kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225434713,"user_tz":300,"elapsed":248,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"b807cd7b-66c1-4a41-8919-dc8e66ff7452"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10, 8, 8, 3)\n","dA_mean = 1.4524377775388075\n","dW_mean = 1.7269914583139097\n","db_mean = 7.839232564616838\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3c771ff44ca1>:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n"]}],"source":["#test: backward_convolution_step\n","np.random.seed(1)\n","A_p = np.random.randn(10, 4, 4, 3)\n","W = np.random.randn(2, 2, 3, 8)\n","b = np.random.randn(1, 1, 1, 8)\n","s={'c_filter':2, 'c_pad' : 2,'c_stride': 2, 'c_filters':8}\n","Z = forward_convolution_step(A_p, s, {'W':W,'b':b})\n","\n","(dA, parameters) = backward_convolution_step(Z, s, (A_p,W))\n","dW=parameters['W']\n","db=parameters['b']\n","\n","print(\"dA_mean =\", np.mean(dA))\n","print(\"dW_mean =\", np.mean(dW))\n","print(\"db_mean =\", np.mean(db))\n","\n","assert dA.shape == (10, 4, 4, 3), f\"Wrong shape for dA  {dA.shape} != (10, 4, 4, 3)\"\n","assert dW.shape == (2, 2, 3, 8), f\"Wrong shape for dW {dW.shape} != (2, 2, 3, 8)\"\n","assert db.shape == (1, 1, 1, 8), f\"Wrong shape for db {db.shape} != (1, 1, 1, 8)\"\n","assert np.isclose(np.mean(dA), 1.4524377), \"Wrong values for dA\"\n","assert np.isclose(np.mean(dW), 1.7269914), \"Wrong values for dW\"\n","assert np.isclose(np.mean(db), 7.8392325), \"Wrong values for db\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2VotF7J26Ks","executionInfo":{"status":"ok","timestamp":1716225435019,"user_tz":300,"elapsed":307,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a9b11950-6c40-4ed5-c6c4-7124d3fef8de"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10, 8, 8, 3)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3c771ff44ca1>:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.07437035971362264"]},"metadata":{},"execution_count":14},{"output_type":"execute_result","data":{"text/plain":["1.2200867898708714"]},"metadata":{},"execution_count":14},{"output_type":"execute_result","data":{"text/plain":["47.125"]},"metadata":{},"execution_count":14}],"source":["#backward_convolutional\n","np.random.seed(1)\n","A_p = np.random.randn(10, 4, 4, 3)\n","W = np.random.randn(2, 2, 3, 8)\n","b = np.random.randn(1, 1, 1, 8)\n","s={'c_filter':2, 'c_pad' : 2,'c_stride': 2, 'c_filters':8, 'activation':'Relu', 'p_stride' : 1, 'p_filter': 2, 'p_function':'max'}\n","Z=forward_convolution_step(A_p, s, {'W':W,'b':b})\n","I=forward_activation_step(Z, s)\n","A=forward_pooling_step(I, s)\n","(m,h,w,c)=A.shape\n","dA=np.random.randn(m,h,w,c)\n","(dA_p, parameters_gradients)=backward_convolutional(dA,s,(I,(A_p,W)))\n","dW=parameters_gradients['W']\n","db=parameters_gradients['b']\n","assert dA_p.shape == (10, 4, 4, 3), f\"Wrong shape for dA  {dA.shape} != (10, 4, 4, 3)\"\n","assert dW.shape == (2, 2, 3, 8), f\"Wrong shape for dW {dW.shape} != (2, 2, 3, 8)\"\n","assert db.shape == (1, 1, 1, 8), f\"Wrong shape for db {db.shape} != (1, 1, 1, 8)\"\n","np.mean(dA_p)\n","np.mean(dW)\n","np.mean(db)\n","assert np.isclose(np.mean(dA_p), 0.0743703), \"Wrong value for dA_p\"\n","assert np.isclose(np.mean(dW), 1.2200867), \"Wrong value for dW\"\n","assert np.isclose(np.mean(db), 47.125), \"Wrong value for db\"\n"]},{"cell_type":"markdown","metadata":{"id":"qpEoJa2k26Ks"},"source":["# **ToDense**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wnPjzYm26Ks","outputId":"a177fd4d-1922-4df0-8f09-afa88370a36c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716225435754,"user_tz":300,"elapsed":2,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18, 5)"]},"metadata":{},"execution_count":15}],"source":["Y = np.random.randn(5, 3, 3, 2)\n","sum_Y = np.sum(Y[3, :, :, 0] + Y[3, :, :, 1])\n","Yf=to_dense(Y)\n","Yf.shape\n","sum_Yf = np.sum(Yf[:, 3])\n","assert Yf.shape == (18, 5), f\"Wrong shape for Yf  {Yf.shape} != (18,5)\"\n","assert np.isclose(sum_Y, sum_Yf), \"Wrong value for values of 3 example\""]},{"cell_type":"markdown","source":["# **Respuesta a Preguntas**"],"metadata":{"id":"ezQHExZw8V7B"}},{"cell_type":"markdown","source":["## PUNTO DOS. TEORIA. ATRAS. CAPA CONVOLUCIÓN 2D.\n","1. Presenten y justifiquen las fórmulas usadas para cada una de las etapas de paso atrás sobre una capa de convolución\n","\n","  A. Paso pooling (mínimo la función MAX)\n","\n","  B. Paso activación\n","\n","  C. Paso convolución\n","\n","  En el código :(\n","\n","2. Definan el contenido del cache necesario para implementar estos pasos\n","\n","- **Para la capa Pooling:**\n","Se guardará la entrada X a la capa pooling que nos servirá para la retropropagación a la hora de calcular el gradiente (Se realiza en forward).\n","cache ---> Entrada X\n","\n","- **Para la capa de activación:**\n","Es necesario almacenar los valores de las activaciones a la hora de la retropapagación.\n","cache ---> Valores de activación\n","\n","## PUNTO CUATRO. CAPA CONVOLUCIÓN 2D A CAPA DENSA\n","\n","1. ¿Cuál es la relación entre las dimensiones de C2D con Densa?\n","\n","La relación entre las dimensiones de la capa de convolución 2D y la capa densa está en la forma en que se transforma la salida de la convolución 2D en una cierta forma para introducirla en la capa densa. En palabras más explicitas, es aplanar la salida de la convolución 2D antes de pasarla a la capa densa."],"metadata":{"id":"J1DBy3bx8cEW"}},{"cell_type":"markdown","source":["# **Retroespectiva**"],"metadata":{"id":"ZpKYbxUItNeG"}},{"cell_type":"markdown","source":["1. ¿Cuál fue el tiempo total invertido en el laboratorio por cada uno de ustedes? (Horas/Nombre)\n","\n","- Juan Pablo: 50 horas\n","- Juan Sebastian: 50 horas\n","\n","2. ¿Cuál es el estado actual del laboratorio? ¿Por qué?\n","\n","Incompleto. Falto implementar bien el framework y probarlo con MNIST.\n","\n","3. ¿Cuál consideran fue el mayor logro? ¿Por qué?\n","\n","Poder implementar bien hacia adelante y hacia atrás, porque habían conceptos que costaban entender, pero aún así se logro resolver.\n","\n","4. ¿Cuál consideran que fue el mayor problema técnico? ¿Qué hicieron para resolverlo?\n","\n","La parte del punto, la de implementar atrás. Para resolverlo investigamos y encontramos páginas donde lo implementaron, y con ello nos basamos para implementar el punto.\n","\n","5. ¿Qué hicieron bien como equipo? ¿Qué se comprometen a hacer para mejorar los resultados?\n","\n","Como equipo supimos trabajar de la mano, el laboratorio se realizó con apoyo mutuo, y cualquier en cualquier inquietud o duda, fuimos capaces de resolverlo. Nos comprometemos a mejorar un poco la distribución de tiempo que a veces se nos queda corta y por ello algunos puntos del laboratorio quedan a medias o sin hacer.\n","\n"],"metadata":{"id":"1dg5FlnmtSdW"}},{"cell_type":"code","source":[],"metadata":{"id":"_sdlpC1aqNRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#forward_convolutional cache\n","#A_p ->[convolutional]-> Z [activation]-> I [pooling]-> A\n","np.random.seed(1)\n","A_p = np.random.randn(10, 4, 4, 3)\n","W = np.random.randn(2, 2, 3, 8)\n","b = np.random.randn(1, 1, 1, 8)\n","s={'c_filter':2, 'c_pad' : 2,'c_stride': 2, 'c_filters':8, 'activation':'Relu', 'p_stride' : 1, 'p_filter': 2, 'p_function':'max'}\n","_,(cI,(cA_p,cW))=forward_convolutional(A_p, s, {'W':W,'b':b})\n","#assert cI.shape == (10,4,4,8)\n","#assert cA_p.shape == (10, 4, 4, 3), f\"Wrong shape for cache A_p {cA_p.shape} != (10, 4, 4, 3)\"\n","#assert cW.shape == (2, 2, 3, 8), f\"Wrong shape for cache W {cW.shape} != (2, 2, 3, 8)\"\n","np.mean(cI)\n","assert np.isclose(np.mean(cI), 0.6083960197084165), \"Wrong value for cache I\"\n","assert np.all(A_p==cA_p), \"Wrong values cache A_p\"\n","assert np.all(W==cW), \"Wrong values cache W\""],"metadata":{"id":"KUdIpovTsIfG","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"error","timestamp":1716773561686,"user_tz":300,"elapsed":157,"user":{"displayName":"juan camargo","userId":"17479442830402474410"}},"outputId":"4be7b586-faf4-4fd2-cea6-861f6441e35e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(10, 8, 8, 3)\n","(10, 4, 4, 8) data_conv\n","(10, 4, 4, 8) data_activation\n","(10, 3, 3, 8) data_out\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-5b540e5a932c>:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  data_out[i, h, w, c] = one_convolution(data_slice,weights,biases)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.056276408216748744"]},"metadata":{},"execution_count":14},{"output_type":"error","ename":"AssertionError","evalue":"Wrong value for cache I","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-8a71eb2011bb>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#assert cW.shape == (2, 2, 3, 8), f\"Wrong shape for cache W {cW.shape} != (2, 2, 3, 8)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6083960197084165\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wrong value for cache I\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_p\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcA_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wrong values cache A_p\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wrong values cache W\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Wrong value for cache I"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["gFS6J6h53YEZ","Bx96YLzk26Kk","8wEnTVws26Kq","qpEoJa2k26Ks","ezQHExZw8V7B","ZpKYbxUItNeG"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}